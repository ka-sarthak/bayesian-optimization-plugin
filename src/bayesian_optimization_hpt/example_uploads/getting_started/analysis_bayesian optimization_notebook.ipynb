{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b340297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-defined block\n",
    "\n",
    "# This notebook has been generated by \"Jupyter Notebook Analysis\" schema.\n",
    "# It gets the data from the entries referenced in the `inputs` sub-section.\n",
    "# It also gets the analysis function based on the analysis type (e.g., XRD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa289f3f-48fd-4cfb-b964-cecea5609f39",
   "metadata": {},
   "source": [
    "## Get the analysis archive\n",
    "\n",
    "Add the `analysis_entry_id` of the corresponding analysis entry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0b5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-defined block\n",
    "\n",
    "analysis_entry_id = \"\"\n",
    "\n",
    "def get_analysis_entry(entry_id: str, url: str = None):\n",
    "    \"\"\"\n",
    "    Gets the entry archive of the analysis entry.\n",
    "\n",
    "    Args:\n",
    "        entry_id (str): Entry ID of the analysis ELN.\n",
    "        url (str): URL of the NOMAD server.\n",
    "\n",
    "    Returns:\n",
    "        EntryArchive: Entry archive of the analysis entry.\n",
    "    \"\"\"\n",
    "\n",
    "    from nomad.client import ArchiveQuery\n",
    "    from nomad.config import config\n",
    "\n",
    "    if url is None:\n",
    "        url = config.client.url\n",
    "\n",
    "    a_query = ArchiveQuery(\n",
    "        query={\n",
    "            'entry_id:any': [entry_id],\n",
    "        },\n",
    "        required='*',\n",
    "        url=url,\n",
    "    )\n",
    "    entry_list = a_query.download()\n",
    "\n",
    "    if not entry_list:\n",
    "        print(\n",
    "            f'Analysis entry with id \"{entry_id}\" not '\n",
    "            f'found at the given URL \"{url}\".'\n",
    "        )\n",
    "        return None\n",
    "    if len(entry_list) > 1:\n",
    "        print('Multiple entries found. Picking the first one.')\n",
    "\n",
    "    return entry_list[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec467c-36fc-49ab-8d3c-8f9bc759f6ab",
   "metadata": {},
   "source": [
    "## Load the schemas defined in your Plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d965de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian_optimization_hpt.schema_packages.schema_package import (\n",
    "    MinMaxScaling, Acquisition, InitialSampling, MinMaxRange,\n",
    "    PassivationPerformanceMeasurement, HydrogenPlasmaTreatment, PassivationPerformanceResult, PassivationPerformanceMeasurementReference,\n",
    "    SurrogateModel, Acquisition\n",
    ")\n",
    "from nomad_analysis.utils import create_entry_with_api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f065c-a57a-4483-a920-53da4836c58b",
   "metadata": {},
   "source": [
    "## Adding the initial samples\n",
    "Uses `create_entry_with_api` to add entries for the inputs\n",
    "- adds `InitialSampling` step to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "015b9bc1-cb72-42d7-975d-a4a1ed9280d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = analysis.m_context.installation_url\n",
    "upload_id = analysis.m_context.upload_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06aac510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n",
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n",
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n",
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n",
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n",
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n",
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n",
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n",
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n",
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n"
     ]
    }
   ],
   "source": [
    "# define the initial set of samples\n",
    "# Create archives for each measurement\n",
    "# Create Initial Sampling step for analysis\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_excel('BO_initial_samples.xlsx')\n",
    "X_name = [\"Process temperature [â„ƒ]\", \"Process time [min]\", \"H2 pressure [Pa]\", \"H2 flow rate [sccm]\", \"RF power [W]\", \"Electrod distance [mm]\"]\n",
    "y_name = [\"Carrier lifetime [um]\"]\n",
    "\n",
    "X = df[X_name]\n",
    "y = df[y_name]\n",
    "\n",
    "sampling = InitialSampling(name='Initial Sampling', samples=[])\n",
    "\n",
    "for i in range(len(df)):\n",
    "    step = HydrogenPlasmaTreatment(\n",
    "        name='H2 plasma treatment',\n",
    "        temperature=X.iloc[i,0],\n",
    "        duration=X.iloc[i,1],\n",
    "        h2_pressure=X.iloc[i,2],\n",
    "        h2_flow_rate=X.iloc[i,3],\n",
    "        rf_power=X.iloc[i,4],\n",
    "        electrode_distance=X.iloc[i,5],\n",
    "    )\n",
    "    result = PassivationPerformanceResult(\n",
    "        name='Passivation performance',\n",
    "        carrier_lifetime=X.iloc[i,0]\n",
    "    )\n",
    "    measurement = PassivationPerformanceMeasurement(\n",
    "        name = f'Initial Sample {i+1}',\n",
    "        steps = [step],\n",
    "        results = [result],\n",
    "    )\n",
    "\n",
    "    # ... in the loop\n",
    "    ref = create_entry_with_api(\n",
    "        section=measurement,\n",
    "        base_url=url,\n",
    "        upload_id=upload_id,\n",
    "        file_name=(\n",
    "            measurement.name.replace(' ', '_') +\n",
    "            '.archive.json'\n",
    "        ),\n",
    "        path='./samples/',\n",
    "    )\n",
    "    sampling.samples.append(\n",
    "        PassivationPerformanceMeasurementReference(\n",
    "            reference=ref\n",
    "        )\n",
    "    )\n",
    "\n",
    "analysis.data.steps.append(sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f69d4a-5101-46fb-a3af-9fe4b07ddc24",
   "metadata": {},
   "source": [
    "## Perform MinMax scaling of the dataset\n",
    "- Adds a `MinMaxScaling` step to the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c79862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the input data using Minmax scaling\n",
    "# Store the min max ranges for each parameter in analysis step\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax=np.array([[50, 0.25, 100, 10, 270, 10],[300,4,700,100, 450, 40]])\n",
    "scaler = MinMaxScaler(feature_range=(0,1), copy=True)\n",
    "scaler.fit(minmax)\n",
    "X1= scaler.transform(X.values)\n",
    "\n",
    "minmax_scaling = MinMaxScaling(\n",
    "    name='Minmax Scaling',\n",
    "    comment=\"\"\"\n",
    "    import numpy from np\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    minmax=np.array([[50, 0.25, 100, 10, 270, 10],[300,4,700,100, 450, 40]])\n",
    "    scaler = MinMaxScaler(feature_range=(0,1), copy=True)\n",
    "    scaler.fit(minmax)\n",
    "    X1= scaler.transform(X)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "for i, key in enumerate(['temperature', 'duration', 'h2_pressure', 'h2_flow_rate', 'rf_power', 'electrode_distance']):\n",
    "    minmax_scaling.min_max_ranges.append(MinMaxRange(name=key, min_value=minmax[0,i], max_value=minmax[1,i]))\n",
    "\n",
    "# ... in a loop, add `minmax_scaling.min_max_ranges`\n",
    "analysis.data.steps.append(minmax_scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bb6ee7-fc48-4a10-a3b2-2c70156b2f21",
   "metadata": {},
   "source": [
    "## Train the Surrogate model and save it\n",
    "- Trains the model, saves the model in `models/` directory\n",
    "- Add path of the model to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76fa6a16-e55c-412c-8b95-52c6be262fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 4 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 5 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified upper bound 30. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train Surrogate model\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import (\n",
    "    RBF, ConstantKernel as C, WhiteKernel as Wh\n",
    ")\n",
    "\n",
    "\n",
    "kernel = (\n",
    "    C(300.0, (1e0, 1e4)) *\n",
    "    RBF([1,1,1,1,1,1], (0.2, 10)) +\n",
    "    Wh(1, (1, 30))\n",
    ")\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "gp.fit(X1, y.values)\n",
    "\n",
    "# pickle the model\n",
    "model_path = \"models/GPSurrogate.pkl\"\n",
    "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "pickle.dump(gp, open(model_path, 'wb'))\n",
    "\n",
    "analysis.data.surrogate_model = SurrogateModel(\n",
    "    name='Gaussian Process Surrogate Model',\n",
    "    model_type=\"Gaussian Process\",\n",
    "    trained_on=sampling.samples,\n",
    "    model_path=model_path,\n",
    ")\n",
    "\n",
    "gp = pickle.load(open(model_path, 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9e7ef-f447-43a5-82f8-dacd95158186",
   "metadata": {},
   "source": [
    "## Define the Acquisition Strategy\n",
    "- defines acquisition function using Upper Confidence Bound method\n",
    "- defines function to get proposal from the BO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b9aeef-d46a-47d4-8d0e-b3daac093d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# define the acquisition function\n",
    "def UpperConfidenceBoundObjective(x):\n",
    "    y_pred, STD = gp.predict(x.reshape(1,-1), return_std=True)\n",
    "    k = 1\n",
    "    return - (y_pred + k * STD)\n",
    "\n",
    "# define class for indexing acquisition in NOMAD\n",
    "class AcquisitionIndexer:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "\n",
    "    def create_sample_archive(self, proposal, carrier_lifetime):\n",
    "        measurement = PassivationPerformanceMeasurement(\n",
    "            name = f'Sample at acquired point {self.count+1}',\n",
    "            steps = [proposal],\n",
    "            results = [\n",
    "                PassivationPerformanceResult(\n",
    "                    name='Passivation performance',\n",
    "                    carrier_lifetime=carrier_lifetime,\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        file_name = measurement.name.replace(' ', '_') + '.archive.json'\n",
    "        ref = create_entry_with_api(section=measurement, base_url=url, upload_id=upload_id, file_name=file_name, path='./samples/')\n",
    "\n",
    "        self.count += 1\n",
    "        return ref\n",
    "\n",
    "def generate_proposal():\n",
    "    x0 = np.random.rand(6)\n",
    "    res = minimize(UpperConfidenceBoundObjective, x0, args=(), method='L-BFGS-B', options={'maxcor': 10, 'ftol': 2.220446049250313e-09, 'gtol': 1e-05, 'eps': 1e-08, 'maxfun': 15000, 'maxiter': 15000, 'iprint': -1, 'maxls': 20})\n",
    "    proposal = scaler.inverse_transform(res.x.reshape(1,-1))[0]\n",
    "\n",
    "    print(res.fun)\n",
    "\n",
    "    proposal = HydrogenPlasmaTreatment(\n",
    "        name='Proposed parameters',\n",
    "        temperature=proposal[0],\n",
    "        duration=proposal[1],\n",
    "        h2_pressure=proposal[2],\n",
    "        h2_flow_rate=proposal[3],\n",
    "        rf_power=proposal[4],\n",
    "        electrode_distance=proposal[5],\n",
    "    )\n",
    "\n",
    "    return proposal\n",
    "\n",
    "acquisition_indexer = AcquisitionIndexer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf5810-d483-4f6c-829a-10baa6544bd9",
   "metadata": {},
   "source": [
    "## Loop to perform Acquisition and retrain the model\n",
    "- Adds `Acquisition` step in the analysis\n",
    "- generates a proposal\n",
    "- creates a sample for the proposal\n",
    "- retrains the model based on it\n",
    "- Updates the analysis archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e5d44c-2922-4fa1-bff3-eca576931f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1204.5668501660953\n",
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified upper bound 30. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/\n",
      "-621.5952215681335\n",
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified upper bound 30. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/\n",
      "-801.122178489229\n",
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/./samples/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified upper bound 30. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending post request @ http://nomad_oasis_proxy/nomad-oasis/api/v1/uploads/xY-Qb7dlQnahl1sbVbYoaQ/raw/\n"
     ]
    }
   ],
   "source": [
    "iters = 0\n",
    "while True:\n",
    "    if iters == 3: break\n",
    "    iters += 1\n",
    "\n",
    "    # generate proposal\n",
    "    proposal = generate_proposal()\n",
    "    x = []\n",
    "    x.append(proposal.temperature.magnitude)\n",
    "    x.append(proposal.duration.magnitude)\n",
    "    x.append(proposal.h2_pressure.magnitude)\n",
    "    x.append(proposal.h2_flow_rate.magnitude)\n",
    "    x.append(proposal.rf_power.magnitude)\n",
    "    x.append(proposal.electrode_distance.magnitude)\n",
    "    x = [x]\n",
    "    x1 = scaler.transform(x)\n",
    "\n",
    "    # acquire a sample at the proposed setting\n",
    "    def simulate_carrier_lifetime():\n",
    "        return 1000*(float(np.random.random()) + 0.5)\n",
    "\n",
    "    y = simulate_carrier_lifetime()\n",
    "    acquisition = Acquisition(\n",
    "        name='Acquisition',\n",
    "        proposal=proposal,\n",
    "        sample=PassivationPerformanceMeasurementReference(\n",
    "            reference=acquisition_indexer.create_sample_archive(proposal, y)\n",
    "        ),\n",
    "    )\n",
    "    analysis.data.steps.append(acquisition)\n",
    "\n",
    "    # retrain the model\n",
    "    gp.fit(x1, [[y]])\n",
    "\n",
    "    # update analysis ELN\n",
    "    create_entry_with_api(\n",
    "        section=analysis,\n",
    "        base_url=url,\n",
    "        upload_id=upload_id,\n",
    "        file_name=analysis.metadata.mainfile\n",
    "    )\n",
    "\n",
    "gp = pickle.load(open(model_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e29171-7b95-44c4-ba36-bc19f6f2e12d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd3f938-f77f-4f84-b67c-52ea44715cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec785a-55c4-422c-8f78-48bf178704cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "trusted": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
